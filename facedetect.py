import cv2
import os
import numpy as np
import base64
import PySimpleGUI as sg
import sys
import shutil

sg.theme('LightBlue3')

# === ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===
embedder = cv2.dnn.readNetFromTorch(
    "/Users/moriwakisou/Desktop/FaceDetect/models/openface_nn4.small2.v1.t7"
)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# === å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ ===
study_dir = "study"
os.makedirs(study_dir, exist_ok=True)

# === ã‚ãªãŸã®é¡”ãƒ‡ãƒ¼ã‚¿ ===
my_embeddings = []
my_face_vector = None


# === çµµæ–‡å­—ã®èª­ã¿è¾¼ã¿ ===
emoji = cv2.imread("img/b.png", cv2.IMREAD_UNCHANGED)

# === é¡”ç‰¹å¾´é‡ã®å­¦ç¿’é–¢æ•° ===
def study_images_from_folder(folder_path):
    global my_embeddings, my_face_vector

    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    if not image_files:
        raise ValueError("å­¦ç¿’ãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    my_embeddings.clear()

    for filename in image_files:
        path = os.path.join(folder_path, filename)
        image = cv2.imread(path)
        if image is None:
            print(f"âš ï¸ èª­ã¿è¾¼ã‚ãªã„ç”»åƒã‚’ã‚¹ã‚­ãƒƒãƒ—: {filename}")
            continue

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.05, 5)

        if len(faces) == 0:
            print(f"âŒ é¡”æ¤œå‡ºå¤±æ•—: {filename}")
            continue

        for (x, y, w, h) in faces:
            face = image[y:y+h, x:x+w]
            blob = cv2.dnn.blobFromImage(
                cv2.resize(face, (96, 96)), 1.0/255, (96, 96),
                (0, 0, 0), swapRB=True, crop=False
            )
            embedder.setInput(blob)
            vec = embedder.forward()
            my_embeddings.append(vec.flatten())

    if len(my_embeddings) == 0:
        raise ValueError("ã©ã®ç”»åƒã‹ã‚‰ã‚‚é¡”ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    my_face_vector = np.mean(my_embeddings, axis=0)
    print(f"âœ… {len(my_embeddings)}æšã®é¡”ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã—ã¾ã—ãŸã€‚")


# === OpenCV â†’ Base64å¤‰æ›é–¢æ•° ===
def cv2_to_base64(img_cv, size=(300, 300)):
    img_resized = cv2.resize(img_cv, size, interpolation=cv2.INTER_AREA)
    _, img_encoded = cv2.imencode(".png", img_resized)
    return base64.b64encode(img_encoded.tobytes())


# === é¡”åˆ¤å®š + çµµæ–‡å­—ãƒã‚¹ã‚¯å‡¦ç† ===
def process_image(img_path):
    if my_face_vector is None:
        raise RuntimeError("âš ï¸ å…ˆã«ã‚ãªãŸã®é¡”ç”»åƒã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")

    with open(img_path, 'rb') as f:
        data = np.fromfile(f, dtype=np.uint8)
    original_img = cv2.imdecode(data, cv2.IMREAD_COLOR)

    if original_img is None:
        raise FileNotFoundError(f"ç”»åƒãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“: {img_path}")

    processed_img = original_img.copy()
    gray = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.05, 5)

    for (x, y, w, h) in faces:
        face = processed_img[y:y+h, x:x+w]
        blob = cv2.dnn.blobFromImage(
            cv2.resize(face, (96, 96)), 1.0/255, (96, 96),
            (0, 0, 0), swapRB=True, crop=False
        )
        embedder.setInput(blob)
        vec = embedder.forward().flatten()

        sim = np.dot(my_face_vector, vec) / (np.linalg.norm(my_face_vector) * np.linalg.norm(vec))

        if sim < 0.9:
            print(f"ğŸ˜ ä»–äººã®é¡”ã‚’æ¤œå‡º (é¡ä¼¼åº¦={sim:.2f})")
            emoji_resized = cv2.resize(emoji, (w, h))
            if emoji_resized.shape[2] == 4:
                alpha_s = emoji_resized[:, :, 3] / 255.0
                alpha_l = 1.0 - alpha_s
                for c in range(3):
                    processed_img[y:y+h, x:x+w, c] = (
                        alpha_s * emoji_resized[:, :, c] +
                        alpha_l * processed_img[y:y+h, x:x+w, c]
                    )
            else:
                processed_img[y:y+h, x:x+w] = emoji_resized

    return original_img, processed_img


# === PySimpleGUI UI ===
image_size = (300, 300)

layout = [
    [sg.Text('', size=(60, 1), key='-STATUS-')],
    [sg.Text("â‘  ã‚ãªãŸã®é¡”ç”»åƒã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰ã—ã¦å­¦ç¿’ãƒ•ã‚©ãƒ«ãƒ€ã«è¿½åŠ ")],
    [sg.Input(key='-FILEPATHS-', enable_events=True, visible=False),
     sg.FilesBrowse('å­¦ç¿’ç”»åƒã‚’è¿½åŠ ', target='-FILEPATHS-', file_types=(("Image Files", "*.png *.jpg *.jpeg"),))],
    [sg.Button('ğŸ“˜ å†å­¦ç¿’ã™ã‚‹'), sg.Button('ğŸ§¹ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ')],

    [sg.Text("â‘¡ åˆ¤å®šã—ãŸã„ç”»åƒã‚’é¸æŠ")],
    [sg.Input(key='-FILEPATH-', enable_events=True, visible=False),
     sg.FileBrowse('åˆ¤å®šç”»åƒã‚’é¸æŠ', target='-FILEPATH-', file_types=(("Image Files", "*.png *.jpg *.jpeg"),))],

    [sg.HSeparator()],
    [
        sg.Column([
            [sg.Text('ã‚ªãƒªã‚¸ãƒŠãƒ«')],
            [sg.Image(size=image_size, key='-IMG_ORIG-')]
        ]),
        sg.VSeparator(),
        sg.Column([
            [sg.Text('å‡¦ç†å¾Œ')],
            [sg.Image(size=image_size, key='-IMG_PROC-')]
        ])
    ]
]

window = sg.Window('OpenCV é¡”èªè­˜ãƒ‡ãƒ¢ (PySimpleGUIç‰ˆ)', layout)

# === ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ— ===
while True:
    event, values = window.read()
    if event == sg.WIN_CLOSED:
        break

    # å­¦ç¿’ç”»åƒè¿½åŠ 
    if event == '-FILEPATHS-':
        filepaths = values['-FILEPATHS-'].split(';')
        for f in filepaths:
            if os.path.exists(f):
                shutil.copy(f, os.path.join(study_dir, os.path.basename(f)))
        window['-STATUS-'].update(f'ğŸ“‚ {len(filepaths)}æšã‚’å­¦ç¿’ãƒ•ã‚©ãƒ«ãƒ€ã«è¿½åŠ ã—ã¾ã—ãŸã€‚')

    # å†å­¦ç¿’
    if event == 'ğŸ“˜ å†å­¦ç¿’ã™ã‚‹':
        try:
            study_images_from_folder(study_dir)
            window['-STATUS-'].update('âœ… å†å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
        
        except Exception as e:
            window['-STATUS-'].update(f'å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}')
            print(e)

    # ğŸ§¹ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
    if event == 'ğŸ§¹ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ':
        try:
            for filename in os.listdir(study_dir):
                file_path = os.path.join(study_dir, filename)
                if os.path.isfile(file_path):
                    os.remove(file_path)
            my_embeddings.clear()
            my_face_vector = None
            window['-STATUS-'].update('ğŸ§¹ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã—ãŸã€‚')
            print("ğŸ§¹ studyãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            window['-STATUS-'].update(f'ãƒªã‚»ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}')
            print(e)

    # åˆ¤å®šç”»åƒã®å‡¦ç†
    if event == '-FILEPATH-':
        img_path = values['-FILEPATH-']
        if img_path:
            try:
                orig, proc = process_image(img_path)
                orig_b64 = cv2_to_base64(orig, size=image_size)
                proc_b64 = cv2_to_base64(proc, size=image_size)
                window['-IMG_ORIG-'].update(data=orig_b64)
                window['-IMG_PROC-'].update(data=proc_b64)
                window['-STATUS-'].update(f'âœ… åˆ¤å®šå®Œäº†: {img_path}')
            except Exception as e:
                window['-STATUS-'].update(f'å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}')
                print(e)

window.close()
